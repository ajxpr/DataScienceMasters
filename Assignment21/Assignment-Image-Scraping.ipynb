{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Topic: Image Scraping\n",
        "\n",
        "### Done By: Akshaj Piri"
      ],
      "metadata": {
        "id": "wDGlVKA53j4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WXkYx5Aj3-yL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec9593d-54f4-4eab-e2c6-dbc50cb41c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT =\"/content/drive/MyDrive/Colab Notebooks/DataScienceMasters2023/Assignments\"\n",
        "import os\n",
        "os.chdir(ROOT)"
      ],
      "metadata": {
        "id": "RntfuLdrWo5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**: Write a python program to extract the video URL of the first five videos."
      ],
      "metadata": {
        "id": "tUqq_MrN3p9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "CU4eO5q_XcaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create a BeautifulSoup object to parse the HTML content\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all the <a> tags containing video links\n",
        "video_links = soup.find_all('a', class_='yt-simple-endpoint style-scope ytd-grid-video-renderer')\n",
        "\n",
        "# Extract the video URLs of the first five videos\n",
        "video_urls = []\n",
        "for link in video_links[:5]:\n",
        "    video_url = \"https://www.youtube.com\" + link['href']\n",
        "    video_urls.append(video_url)\n",
        "\n",
        "# Print the video URLs\n",
        "for url in video_urls:\n",
        "    print(url)"
      ],
      "metadata": {
        "id": "6gWheQQMXhEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**: Write a python program to extract the URL of the video thumbnails of the first five videos."
      ],
      "metadata": {
        "id": "UggGCJWv32Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_video_thumbnails(channel_link):\n",
        "    response = requests.get(channel_link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    video_thumbnails = []\n",
        "    video_links = soup.find_all('a', class_='yt-simple-endpoint style-scope ytd-grid-video-renderer')\n",
        "\n",
        "    for i in range(min(5, len(video_links))):\n",
        "        video_url = 'https://www.youtube.com' + video_links[i]['href']\n",
        "        response = requests.get(video_url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        thumbnail_element = soup.find('meta', property='og:image')\n",
        "        thumbnail_url = thumbnail_element['content'] if thumbnail_element else None\n",
        "        video_thumbnails.append(thumbnail_url)\n",
        "\n",
        "    return video_thumbnails\n",
        "\n",
        "# Provide the YouTube channel link\n",
        "channel_link = 'https://www.youtube.com/@PW-Foundation/videos'\n",
        "\n",
        "thumbnails = get_video_thumbnails(channel_link)\n",
        "\n",
        "# Printing the URLs of the video thumbnails\n",
        "for thumbnail_url in thumbnails:\n",
        "    print(thumbnail_url)"
      ],
      "metadata": {
        "id": "IsgFzfqh35yq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**: Write a python program to extract the title of the first five videos."
      ],
      "metadata": {
        "id": "1ejvEmWp32dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_video_titles(channel_link):\n",
        "    response = requests.get(channel_link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    video_titles = []\n",
        "    video_elements = soup.select('.yt-lockup-title > a')\n",
        "\n",
        "    for i in range(min(5, len(video_elements))):\n",
        "        video_title = video_elements[i].text.strip()\n",
        "        video_titles.append(video_title)\n",
        "\n",
        "    return video_titles\n",
        "\n",
        "# Provide the YouTube channel link\n",
        "channel_link = 'https://www.youtube.com/@PW-Foundation/videos'\n",
        "\n",
        "titles = get_video_titles(channel_link)\n",
        "\n",
        "# Printing the titles of the first five videos\n",
        "for title in titles:\n",
        "    print(title)"
      ],
      "metadata": {
        "id": "63euDfdu37Do"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**: Write a python program to extract the number of views of the first five videos."
      ],
      "metadata": {
        "id": "2YmJpW-H32hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_video_views(channel_link):\n",
        "    response = requests.get(channel_link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    video_views = []\n",
        "    view_elements = soup.select('.yt-lockup-meta-info li:nth-of-type(1)')\n",
        "\n",
        "    for i in range(min(5, len(view_elements))):\n",
        "        view_text = view_elements[i].text.strip()\n",
        "        video_views.append(view_text)\n",
        "\n",
        "    return video_views\n",
        "\n",
        "# Provide the YouTube channel link\n",
        "channel_link = 'https://www.youtube.com/@PW-Foundation/videos'\n",
        "\n",
        "views = get_video_views(channel_link)\n",
        "\n",
        "# Printing the number of views of the first five videos\n",
        "for view in views:\n",
        "    print(view)"
      ],
      "metadata": {
        "id": "_zlyXstv385X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**: Write a python program to extract the time of posting of video for the first five videos."
      ],
      "metadata": {
        "id": "RceIbI0J32k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_video_posting_time(channel_link):\n",
        "    response = requests.get(channel_link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    posting_times = []\n",
        "    time_elements = soup.select('.yt-lockup-meta-info li:nth-of-type(2)')\n",
        "\n",
        "    for i in range(min(5, len(time_elements))):\n",
        "        time_text = time_elements[i].text.strip()\n",
        "        posting_times.append(time_text)\n",
        "\n",
        "    return posting_times\n",
        "\n",
        "# Provide the YouTube channel link\n",
        "channel_link = 'https://www.youtube.com/@PW-Foundation/videos'\n",
        "\n",
        "times = get_video_posting_time(channel_link)\n",
        "\n",
        "# Printing the time of posting for the first five videos\n",
        "for time in times:\n",
        "    print(time)"
      ],
      "metadata": {
        "id": "Q86CeiPI39_r"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}